# -*- coding: utf-8 -*-
"""amazon review.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uGotAS-UdkBV36jlFDg9UrOwXSMgqymG

# Getting Data
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install wordcloud

# Commented out IPython magic to ensure Python compatibility.
# %pip install spellchecker

pip install pyspellchecker

import gzip
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.stem.porter import PorterStemmer
import nltk
from nltk.corpus.reader import PlaintextCorpusReader
import os
import spacy
import re
from nltk.stem import WordNetLemmatizer
from collections import Counter
from sklearn.feature_extraction.text import CountVectorizer
from wordcloud import WordCloud
import re
import nltk
#from spellchecker import SpellChecker
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

from sklearn.preprocessing import MinMaxScaler
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
import pickle

def parse(path):
  g = gzip.open(path, 'r')
  for l in g:
    yield json.loads(l)

def getDF(path):
  i = 0
  df = {}
  for d in parse(path):
    df[i] = d
    i += 1
  return pd.DataFrame.from_dict(df, orient='index')

lb_path = "/content/drive/MyDrive/Luxury_Beauty_5.json.gz"
parse(lb_path)
LuxuryBeauty = getDF(lb_path)

f_path = "/content/drive/MyDrive/AMAZON_FASHION_5.json.gz"
parse(f_path)
AmazonFashion = getDF(f_path)

ab_path = "/content/drive/MyDrive/All_Beauty_5.json.gz"
parse(ab_path)
AllBeauty = getDF(ab_path)

app_path = "/content/drive/MyDrive/Appliances_5.json.gz"
parse(app_path)
Appliances = getDF(app_path)

industrial_path = "/content/drive/MyDrive/Industrial_and_Scientific_5.json.gz"
parse(industrial_path)
IndustrialAndScientific = getDF(industrial_path)

s_path = "/content/drive/MyDrive/Software_5.json.gz"
parse(s_path)
Software = getDF(s_path)

music = "/content/drive/MyDrive/Digital_Music_5.json.gz"
parse(music)
DigitalMusic = getDF(music)

path_v = "/content/drive/MyDrive/Video_Games_5.json.gz"
parse(path_v)
VideoGame = getDF(path_v)

path_mi = "/content/drive/MyDrive/Musical_Instruments_5.json.gz"
parse(path_mi)
MusicalInstrument = getDF(path_mi)

path_g = "/content/drive/MyDrive/Gift_Cards_5.json.gz"
parse(path_g)
GiftCard = getDF(path_g)

path_ms= "/content/drive/MyDrive/Magazine_Subscriptions_5.json.gz"
parse(path_ms)
MagazineSubs = getDF(path_ms)

path_art = "/content/drive/MyDrive/Arts_Crafts_and_Sewing_5.json.gz"
parse(path_art)
Art = getDF(path_art)

dfs_list = [LuxuryBeauty, AmazonFashion, AllBeauty, Appliances, IndustrialAndScientific, Software, DigitalMusic, VideoGame, MusicalInstrument, GiftCard, MagazineSubs, Art ]
AllProducts = pd.concat(dfs_list, ignore_index=True)
AllProducts.reset_index(drop=True, inplace=True)

AllProducts.info()

names_list = ["Luxury Beauty", "Amazon Fashion", "All Beauty", "Appliances", "Industrial And Scientific", "Software","DigitalMusic", "VideoGame", "MusicalInstrument", "GiftCard", "MagazineSubs", "Art"]

# Plot ratings distribution for each dataset
for df, name in zip(dfs_list, names_list):
    ratings = df['overall']
    plt.figure(figsize=(8, 6))
    plt.hist(ratings, bins=5, edgecolor='black', alpha=0.7)
    plt.xlabel('Rating')
    plt.ylabel('Frequency')
    plt.title(f'Distribution of Ratings for {name} Dataset')
    plt.xticks(range(1, 6))
    plt.grid(False)
    plt.show()

# Plot overall ratings distribution
plt.figure(figsize=(8, 6))
plt.hist(AllProducts['overall'], bins=5, edgecolor='black', alpha=0.7)
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.title('Overall Distribution of Ratings')
plt.xticks(range(1, 6))
plt.grid(False)
plt.show()

rating_1_count = len(AllProducts[AllProducts['overall'] == 1])
print("Number of samples with rating 1:", rating_1_count)

AllProducts = AllProducts.sample(frac=1, random_state=42)
AllProducts.reset_index(drop=True, inplace=True)

AllProducts.head()

AllProducts['reviewText'] = AllProducts['reviewText'].astype(str)
AllProducts['summary'] = AllProducts['summary'].astype(str)

columns_to_drop = [col for col in AllProducts.columns if col not in ['reviewText', 'overall','summary','verified']]
AllProducts.drop(columns_to_drop, axis=1, inplace=True)

AllProducts=AllProducts[AllProducts['verified']==True]

AllProducts.info()

AllProducts = AllProducts.dropna(subset=['reviewText','summary'])

rating_1_count = len(AllProducts[AllProducts['overall'] == 1])
print("Number of samples with rating 1:", rating_1_count)

rating_2_count = len(AllProducts[AllProducts['overall'] == 2])
print("Number of samples with rating 2:", rating_2_count)

AllProducts=AllProducts[['overall','reviewText','summary']]

AllProducts['review'] = AllProducts['reviewText'] + ' ' + AllProducts['summary']

AllProducts=AllProducts[['overall','review']]

AllProducts.reset_index(drop=True, inplace=True)

AllProducts.head()

AllProducts['review'][0]

AllProducts['overall'].value_counts()

df1 = pd.DataFrame()


for rating in range(1, 6):
    rating_samples = AllProducts[AllProducts['overall'] == rating]
    sampled_rows = rating_samples.sample(n=5000, replace=False)
    df1 = pd.concat([df1, sampled_rows], ignore_index=True)

df1.info()

df1.describe()

plt.figure(figsize=(8, 6))
plt.hist(df1['overall'], bins=5, edgecolor='black', alpha=0.7,rwidth=0.9)
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.title('Overall Distribution of Ratings in final train dataset')
plt.xticks(range(1, 6))
plt.grid(False)
plt.show()

df1 = df1.sample(frac=1, random_state=42)
df1.reset_index(drop=True, inplace=True)

df1.reset_index(drop=True, inplace=True)

df1.head()

"""# Data Preprocessing

## Lower
"""

df1["cleaned_review"]=df1["review"].str.lower()

df1.head()

"""## Handling data with apostrophe"""

appos = {
"aren't" : "are not",
"can't" : "cannot",
"couldn't" : "could not",
"didn't" : "did not",
"doesn't" : "does not",
"don't" : "do not",
"hadn't" : "had not",
"hasn't" : "has not",
"haven't" : "have not",
"he'd" : "he would",
"he'll" : "he will",
"he's" : "he is",
"i'd" : "I would",
"i'd" : "I had",
"i'll" : "I will",
"i'm" : "I am",
"isn't" : "is not",
"it's" : "it is",
"it'll":"it will",
"i've" : "I have",
"let's" : "let us",
"mightn't" : "might not",
"mustn't" : "must not",
"shan't" : "shall not",
"she'd" : "she would",
"she'll" : "she will",
"she's" : "she is",
"shouldn't" : "should not",
"that's" : "that is",
"there's" : "there is",
"they'd" : "they would",
"they'll" : "they will",
"they're" : "they are",
"they've" : "they have",
"we'd" : "we would",
"we're" : "we are",
"weren't" : "were not",
"we've" : "we have",
"what'll" : "what will",
"what're" : "what are",
"what's" : "what is",
"what've" : "what have",
"where's" : "where is",
"who'd" : "who would",
"who'll" : "who will",
"who're" : "who are",
"who's" : "who is",
"who've" : "who have",
"won't" : "will not",
"wouldn't" : "would not",
"you'd" : "you would",
"you'll" : "you will",
"you're" : "you are",
"you've" : "you have",
"'re": " are",
"wasn't": "was not",
"we'll":" will",
"didn't": "did not"
}

def apply_mapping(row):
  review = row['cleaned_review']
  for key, value in appos.items():
    review = review.replace(key, value)
  return review

df1['cleaned_review'] = df1.apply(apply_mapping, axis=1)

df1.head(30)

"""## Removing Punctuation"""

import string
exclude=string.punctuation

def remove_punc(text):
    if isinstance(text, str):
        for char in exclude:
            text = text.replace(char, ' ')
        return text
    else:
        return str(text)

df1['cleaned_review']=df1['cleaned_review'].apply(remove_punc)

df1.head()

"""## Removing numbers"""

def remove_numbers(text):
    return re.sub(r'\d+', '', text)

# Apply the function to the 'review' column
df1['cleaned_review'] = df1['cleaned_review'].apply(remove_numbers)

"""## Removing HTML Tags"""

def remove_html_tag(text):
    pattern = re.compile('<.*?>')
    return pattern.sub(r'',text)

df1['cleaned_review']=df1['cleaned_review'].apply(remove_html_tag)

"""## Removing \n"""

df1['cleaned_review'] = df1['cleaned_review'].apply(lambda x: x.replace("\n"," "))

df1['cleaned_review'][19666]

df1['cleaned_review'] = df1['cleaned_review'].str.replace(' +', ' ')

df1['review'][19666]

df1['cleaned_review'][19666]

"""## Removing Stopwords"""

from nltk.tokenize import word_tokenize

stop_words = set(stopwords.words('english'))
df1['cleaned_review'] = df1['cleaned_review'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))

df1

"""## Stemming"""

stemmer = nltk.PorterStemmer()
# Stem the reviews column
df1['cleaned_review'] = df1['cleaned_review'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))

"""## Lemmatization"""

from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
df1['cleaned_review'] = df1['cleaned_review'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split(' ')]))

"""## Removing words with underscore or words with length less than 3

"""

def remove_single_letters_and_underscore_words(text):
    words = text.split()
    filtered_words = [word for word in words if len(word) > 2 and '_' not in word]
    return ' '.join(filtered_words)

df1['cleaned_review'] = df1['cleaned_review'].apply(remove_single_letters_and_underscore_words)

df1

"""## Removing words like one star

"""

# Define words to remove
words_to_remove = ['one', 'two', 'three', 'four', 'five', 'star', 'stars','game', 'games', 'music', 'song', 'product', 'products']

# Define a function to remove specific words from text
def remove_specific_words(text):
    pattern = r'\b(?:' + '|'.join(words_to_remove) + r')\b'
    return re.sub(pattern, '', text)

# Apply the function to the 'cleaned_review' column
df1['cleaned_review'] = df1['cleaned_review'].apply(remove_specific_words)

df1

"""# Analysis of reviews"""

cv = CountVectorizer(stop_words='english')
words = cv.fit_transform(df1.review)

# Combine all reviews
reviews = " ".join([review for review in df1['cleaned_review']])
# Initialize wordcloud object
wc = WordCloud(background_color='white', max_words = 150)
# Generate and plot wordcloud
plt.figure(figsize=(10,10))
plt.imshow(wc.generate(reviews))
plt.title('Wordcloud for all reviews', fontsize=10)
plt.axis('off')
plt.show()

# Extract positive reviews (ratings 3, 4, 5)
positive_reviews = df1[df1['overall'].isin([3, 4, 5])]['cleaned_review']

# Join positive reviews into a single string
positive_reviews_str = ' '.join(positive_reviews)

# Extract negative reviews (ratings 1, 2)
negative_reviews = df1[df1['overall'].isin([1, 2])]['cleaned_review']

# Join negative reviews into a single string
negative_reviews_str = ' '.join(negative_reviews)

# Create WordCloud objects for positive and negative reviews
positive_wc = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews_str)
negative_wc = WordCloud(width=800, height=400, background_color='white').generate(negative_reviews_str)

# Plot word clouds
plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
plt.imshow(positive_wc, interpolation='bilinear')
plt.title('Word Cloud for Positive Reviews')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(negative_wc, interpolation='bilinear')
plt.title('Word Cloud for Negative Reviews')
plt.axis('off')

plt.show()

reviews = df1['cleaned_review'].tolist()
vectorizer = CountVectorizer(max_features=50)
vectorizer.fit(reviews)
word_counts = vectorizer.transform(reviews)
total_word_counts = word_counts.sum(axis=0)
vocabulary = vectorizer.get_feature_names_out()
word_frequencies = [(vocabulary[i], total_word_counts[0, i]) for i in range(len(vocabulary))]
word_frequencies.sort(key=lambda x: x[1], reverse=True)

print("Top 50 words with their frequencies:")
for word, frequency in word_frequencies[:50]:
    print(f"{word}: {frequency}")

reviews = df1['cleaned_review'].tolist()
vectorizer = CountVectorizer(max_features=150)
vectorizer.fit(reviews)
word_counts = vectorizer.transform(reviews)
total_word_counts = word_counts.sum(axis=0)
vocabulary = vectorizer.get_feature_names_out()
word_frequencies = [(vocabulary[i], total_word_counts[0, i]) for i in range(len(vocabulary))]
word_frequencies.sort(key=lambda x: x[1], reverse=True)

print("Top 50 words with their frequencies:")
for word, frequency in word_frequencies[:150]:
    print(f"{word}: {frequency}")

vectorizer = CountVectorizer(ngram_range=(2, 2))
vectorizer.fit(reviews)
word_counts = vectorizer.transform(reviews)
total_word_counts = word_counts.sum(axis=0)
vocabulary = vectorizer.get_feature_names_out()
word_frequencies = [(vocabulary[i], total_word_counts[0, i]) for i in range(len(vocabulary))]
word_frequencies.sort(key=lambda x: x[1], reverse=True)

print("Top 20 bigrams with their frequencies:")
for word, frequency in word_frequencies[:20]:
    print(f"{word}: {frequency}")

vectorizer = CountVectorizer(ngram_range=(3, 3))
vectorizer.fit(reviews)
word_counts = vectorizer.transform(reviews)
total_word_counts = word_counts.sum(axis=0)
vocabulary = vectorizer.get_feature_names_out()
trigram_frequencies = [(vocabulary[i], total_word_counts[0, i]) for i in range(len(vocabulary))]
trigram_frequencies.sort(key=lambda x: x[1], reverse=True)

print("Top 20 trigrams with their frequencies:")
for trigram, frequency in trigram_frequencies[:20]:
    print(f"{trigram}: {frequency}")

"""# Prediction of Ratings - Multi Class

## Using CountVectorizer to initialize weights for word embeddings
"""

vectorizer = CountVectorizer(max_features=10000)

X = vectorizer.fit_transform(df1['cleaned_review'])

from sklearn.model_selection import train_test_split

# Assume X and y are your features and labels
# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df1['overall'], test_size=0.2, shuffle = False)

"""### MultiNomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

import random

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gaussian NaiveBayes"""

vectorizer = CountVectorizer(max_features=2500)

X = vectorizer.fit_transform(df1['cleaned_review'])

from sklearn.model_selection import train_test_split

# Assume X and y are your features and labels
# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

vectorizer = CountVectorizer(max_features=10000)

X = vectorizer.fit_transform(df1['cleaned_review'])

from sklearn.model_selection import train_test_split

# Assume X and y are your features and labels
# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - entroy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 Trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 trees

"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 100 trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""## Using Tf-Idf for weights initialization"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=10000, stop_words='english')
tfidf=tfidf_vectorizer.fit_transform(df1['cleaned_review'])

tfidf.shape

X_train, X_test, y_train, y_test = train_test_split(tfidf, df1['overall'], test_size=0.2, shuffle = False)

"""### Multinomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gausian Naive Bayes"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=2000, stop_words='english')
tfidf=tfidf_vectorizer.fit_transform(df1['cleaned_review'])

tfidf.shape

X_train, X_test, y_train, y_test = train_test_split(tfidf, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=10000, stop_words='english')
tfidf=tfidf_vectorizer.fit_transform(df1['cleaned_review'])

tfidf.shape

X_train, X_test, y_train, y_test = train_test_split(tfidf, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - entropy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 Trees"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random forest - 100 Trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""## Using bigrams for initializing weights to word embeddings"""

cv = CountVectorizer(ngram_range=(1,2), max_features = 7000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### MultiNomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gaussian Naive Bayes"""

cv = CountVectorizer(ngram_range=(1,2), max_features = 2000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

cv = CountVectorizer(ngram_range=(1,2), max_features = 7000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - Entropy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 trees"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 100 trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""## Using trigrams for initializing weights to word embeddings"""

cv = CountVectorizer(ngram_range=(1,3), max_features = 10000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### MultiNomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gaussian Naive Bayes"""

cv = CountVectorizer(ngram_range=(1,3), max_features = 2000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])



cv = CountVectorizer(ngram_range=(1,3), max_features = 10000)
traindata = cv.fit_transform(df1['cleaned_review'])

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - Entropy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 trees"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 100 trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""# Binary classification of ratings"""

category_mapping = {
    1.0: '0',
    2.0: '0',
    3.0: '1',
    4.0: '1',
    5.0: '1',
}

df1['overall'] =df1['overall'].replace(category_mapping)

"""## Using CountVectorizer to initialize weights for word embeddings"""

vectorizer = CountVectorizer(max_features=10000)

X = vectorizer.fit_transform(df1['cleaned_review'])

from sklearn.model_selection import train_test_split

# Assume X and y are your features and labels
# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df1['overall'], test_size=0.2, shuffle = False)

"""### MultiNomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

import random

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gaussian NaiveBayes"""

vectorizer = CountVectorizer(max_features=2500)

X = vectorizer.fit_transform(df1['cleaned_review'])

from sklearn.model_selection import train_test_split

# Assume X and y are your features and labels
# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

vectorizer = CountVectorizer(max_features=10000)

X = vectorizer.fit_transform(df1['cleaned_review'])

from sklearn.model_selection import train_test_split

# Assume X and y are your features and labels
# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - entroy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 Trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 trees

"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 100 trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""## Using Tf-Idf for weights initialization"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=10000, stop_words='english')
tfidf=tfidf_vectorizer.fit_transform(df1['cleaned_review'])

tfidf.shape

X_train, X_test, y_train, y_test = train_test_split(tfidf, df1['overall'], test_size=0.2, shuffle = False)

"""### Multinomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gausian Naive Bayes"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=2000, stop_words='english')
tfidf=tfidf_vectorizer.fit_transform(df1['cleaned_review'])

tfidf.shape

X_train, X_test, y_train, y_test = train_test_split(tfidf, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=10000, stop_words='english')
tfidf=tfidf_vectorizer.fit_transform(df1['cleaned_review'])

tfidf.shape

X_train, X_test, y_train, y_test = train_test_split(tfidf, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - entropy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 Trees"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random forest - 100 Trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""## Using bigrams for initializing weights to word embeddings"""

cv = CountVectorizer(ngram_range=(1,2), max_features = 7000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### MultiNomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gaussian Naive Bayes"""

cv = CountVectorizer(ngram_range=(1,2), max_features = 2000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

cv = CountVectorizer(ngram_range=(1,2), max_features = 7000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - Entropy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 trees"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 100 trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""## Using trigrams for initializing weights to word embeddings"""

cv = CountVectorizer(ngram_range=(1,3), max_features = 10000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### MultiNomial Naive Bayes"""

MultinomialNaiveBayes = MultinomialNB()
MultinomialNaiveBayes.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred = MultinomialNaiveBayes.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Gaussian Naive Bayes"""

cv = CountVectorizer(ngram_range=(1,3), max_features = 2000)
traindata = cv.fit_transform(df1['cleaned_review'])

traindata.shape

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

GaussianNaiveBayes = GaussianNB()
GaussianNaiveBayes.fit(X_train.toarray(), y_train)

y_pred = GaussianNaiveBayes.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])



cv = CountVectorizer(ngram_range=(1,3), max_features = 10000)
traindata = cv.fit_transform(df1['cleaned_review'])

X_train, X_test, y_train, y_test = train_test_split(traindata, df1['overall'], test_size=0.2, shuffle = False)

"""### Decision Tree - Entropy"""

dt_entropy = DecisionTreeClassifier(criterion='entropy') # Decision tree with entropy criterion
dt_entropy.fit(X_train, y_train)

y_pred = dt_entropy.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Decision Tree - Gini"""

dt_gini = DecisionTreeClassifier(criterion='gini') # Decision tree with gini criterion
dt_gini.fit(X_train, y_train)

y_pred = dt_gini.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 20 trees"""

rf_20 = RandomForestClassifier(n_estimators=20) # Random forest with 20 trees
rf_20.fit(X_train, y_train)

y_pred = rf_20.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 50 trees"""

rf_50 = RandomForestClassifier(n_estimators=50) # Random forest with 20 trees
rf_50.fit(X_train, y_train)

y_pred = rf_50.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])

"""### Random Forest - 100 trees"""

rf_100 = RandomForestClassifier(n_estimators=100) # Random forest with 20 trees
rf_100.fit(X_train, y_train)

y_pred = rf_100.predict(X_test.toarray())
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred))

conf_mat = confusion_matrix(y_test, y_pred)

# Create a heatmap using seaborn
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

misclassified_indices = np.where(y_test != y_pred)[0]

index1 = random.choice(misclassified_indices)
index2 = random.choice(misclassified_indices)


print("Misclassified Review:", df1['review'][index1+20000])
print("Predicted label:", y_pred[index1])
print("True label:", y_test[index1+20000])

print("\n") # Add newline character for better readability

print("Another Misclassified Review:", df1['review'][index2+20000])
print("Predicted label:", y_pred[index2])
print("True label:", y_test[index2+20000])